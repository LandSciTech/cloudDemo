<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Setting up cloud processing with Azure Batch • cloudDemo</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Setting up cloud processing with Azure Batch">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">cloudDemo</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/cliCommands.html">Useful Azure CLI commands</a></li>
    <li><a class="dropdown-item" href="../articles/cloudSetup.html">Setting up cloud processing with Azure Batch</a></li>
    <li><a class="dropdown-item" href="../articles/parallelization.html">Parallelization</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/see24/cloudDemo/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Setting up cloud processing with Azure Batch</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/see24/cloudDemo/blob/master/vignettes/cloudSetup.Rmd" class="external-link"><code>vignettes/cloudSetup.Rmd</code></a></small>
      <div class="d-none name"><code>cloudSetup.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="background">Background<a class="anchor" aria-label="anchor" href="#background"></a>
</h2>
<p>Azure Batch is one of many Azure services that can be used to run
analyses in the cloud. It uses a hierarchy of <strong>Pools</strong>
which contain <strong>Jobs</strong> which contain
<strong>Tasks</strong>. A <strong>Pool</strong> is a group of
<strong>Nodes</strong> (similar to virtual machines) which are the
computers that will run the analyses. When a pool is created you choose
the number of nodes and configure the operating system, RAM and number
of cores that each node will have. <strong>Jobs</strong> are used for
scheduling different related tasks, in simple cases they are just a
folder that contains your tasks. <strong>Tasks</strong> contain the code
that you want the node to run and information on where to get data from
and save it to.</p>
<p>There are several options available for interacting with Azure Batch
including the Azure <a href="https://portal.azure.com/" class="external-link">web portal</a>
and the Azure command line interface (CLI). This tutorial will focus on
the Azure CLI method since it is the simplest and fastest method. In
both cases you need to be on the ECCC network to access the cloud,
either in the office or on VPN. Azure CLI can be used on any terminal in
Windows but the code below is written assuming you are using a Bash
Terminal and will not run exactly as written in other terminals.</p>
</div>
<div class="section level2">
<h2 id="get-access">Get Access<a class="anchor" aria-label="anchor" href="#get-access"></a>
</h2>
<p>To be added to the LERS Azure Batch account email Sarah Endicott, she
will email the CCOE (Cloud Centre of Expertise) to ask them to give your
account the required permissions. I recommend allowing a week for this
process.</p>
</div>
<div class="section level2">
<h2 id="install-azure-cli">Install Azure CLI<a class="anchor" aria-label="anchor" href="#install-azure-cli"></a>
</h2>
<div class="section level3">
<h3 id="azure-cli">Azure CLI<a class="anchor" aria-label="anchor" href="#azure-cli"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Install using install wizard <a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-windows?tabs=azure-cli#install-or-update" class="external-link uri">https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-windows?tabs=azure-cli#install-or-update</a>
If you don’t have <a href="https://ecollab.ncr.int.ec.gc.ca/org/11001/Shared%20Documents/Elevated%20Privileges%20Request%20Form_v4.0.pdf" class="external-link">elevated
privileges</a> you will need to call service desk to have them complete
the installation for you.</li>
</ol>
</div>
</div>
<div class="section level2">
<h2 id="use-azure-cli-to-run-an-analysis">Use Azure CLI to run an analysis<a class="anchor" aria-label="anchor" href="#use-azure-cli-to-run-an-analysis"></a>
</h2>
<div class="section level3">
<h3 id="sign-in">Sign in<a class="anchor" aria-label="anchor" href="#sign-in"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Run <code>az login</code> in the terminal. This will open a web
browser for you to login.</li>
<li>Run
<code>az batch account login -g EcDc-WLS-rg -n ecdcwlsbatch</code> to
connect to the “EcDc-WLS-rg” resource group and “ecdcwlsbatch” service
name.</li>
<li>Run <code>az batch pool list</code> to show any existing pools.
<em>Note: if you get an error at this point saying “This request is not
authorized to perform this operation.” you are likely not signed on to
the VPN, sign on and try again.</em>
</li>
</ol>
</div>
<div class="section level3">
<h3 id="create-a-pool">Create a pool<a class="anchor" aria-label="anchor" href="#create-a-pool"></a>
</h3>
<p>You can create a pool from the CLI either by providing the
configuration as individual arguments or by supplying a JSON file. I use
the JSON file option because then it is easy to modify previous versions
and not all functionality is available as an argument.</p>
<p>A template JSON file is provided in this repository under
cloud_config/template_pool_cli.json. Some parts of the JSON file should
stay the same in most cases while others will need to be adjusted based
on the type of pool you want to build.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>    <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"Microsoft.Batch/batchAccounts/pools"</span><span class="fu">,</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>    <span class="dt">"apiVersion"</span><span class="fu">:</span> <span class="st">"2016-12-01"</span><span class="fu">,</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>    <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"test_pool_json_cli"</span><span class="fu">,</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>    <span class="dt">"vmSize"</span><span class="fu">:</span> <span class="st">"standard_A1_v2"</span><span class="fu">,</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>    <span class="dt">"virtualMachineConfiguration"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>        <span class="dt">"imageReference"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>            <span class="dt">"publisher"</span><span class="fu">:</span> <span class="st">"microsoft-azure-batch"</span><span class="fu">,</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>            <span class="dt">"offer"</span><span class="fu">:</span> <span class="st">"ubuntu-server-container"</span><span class="fu">,</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>            <span class="dt">"sku"</span><span class="fu">:</span> <span class="st">"20-04-lts"</span><span class="fu">,</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>            <span class="dt">"version"</span><span class="fu">:</span> <span class="st">"latest"</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>        <span class="fu">},</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>        <span class="dt">"nodeAgentSKUId"</span><span class="fu">:</span> <span class="st">"batch.node.ubuntu 20.04"</span><span class="fu">,</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>        <span class="dt">"containerConfiguration"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>          <span class="dt">"type"</span><span class="fu">:</span> <span class="st">"dockerCompatible"</span><span class="fu">,</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>          <span class="dt">"containerImageNames"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>            <span class="st">"rocker/r-bspm:jammy"</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>          <span class="ot">]</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>        <span class="fu">},</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>        <span class="dt">"nodePlacementConfiguration"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>          <span class="dt">"policy"</span><span class="fu">:</span> <span class="st">"regional"</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>        <span class="fu">}</span></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>    <span class="fu">},</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>        <span class="dt">"targetDedicatedNodes"</span><span class="fu">:</span> <span class="dv">1</span><span class="fu">,</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>    <span class="dt">"networkConfiguration"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>        <span class="dt">"subnetId"</span><span class="fu">:</span><span class="st">"/subscriptions/8bc16bb2-5633-480b-8f4c-3ba6a6c769b4/resourceGroups/EcDc-WLS-rg/providers/Microsoft.Network/virtualNetworks/EcDc-WLS-vnet/subnets/EcDc-WLS_compute-cluster-snet"</span></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>        <span class="fu">}</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<div class="section level4">
<h4 id="fields-to-edit">Fields to edit:<a class="anchor" aria-label="anchor" href="#fields-to-edit"></a>
</h4>
<ul>
<li>id: Give the pool a name. It should start with the first letter of
your first name and your last name so we can differentiate them to track
billing eg “sendicott_test_pool”</li>
<li>vmSize: This is the family of VM and the number of CPUs different
families will have different # CPU to RAM ratios. We have access to a
subset of VM families with a <a href="https://portal.azure.com/#@007gc.onmicrosoft.com/resource/subscriptions/8bc16bb2-5633-480b-8f4c-3ba6a6c769b4/resourceGroups/EcDc-WLS-rg/providers/Microsoft.Batch/batchAccounts/ecdcwlsbatch/accountQuotas" class="external-link">quota</a>
for each one. See this <a href="https://learn.microsoft.com/en-us/azure/virtual-machines/sizes" class="external-link">Microsoft
website</a> for some details on the different families. The easiest way
to filter the options and choose a size is to go to the Azure portal
&gt; Batch &gt; <a href="https://portal.azure.com/#@007gc.onmicrosoft.com/resource/subscriptions/8bc16bb2-5633-480b-8f4c-3ba6a6c769b4/resourceGroups/EcDc-WLS-rg/providers/Microsoft.Batch/batchAccounts/ecdcwlsbatch/accountPools" class="external-link">Pools
page</a> and click “Add” and then scroll to vmSize and follow the link
for “View full pricing details”. In this example we use
“Standard_A1_v2”. All the names start with “Standard_” and then you
substitute the sku which contains the Family, # CPUs and version.</li>
<li>targetDedicatedNodes: The number of nodes to have in the pool.
Typically 1 if you are going to run one task that might use multiple
cores on one machine for parallelization or one for each task you want
to run on a separate machine.</li>
<li>containerImageNames: The name of the docker image that you want to
use. This will pre-fetch this docker image for use with your tasks. You
can enter the name of any <a href="https://hub.docker.com/" class="external-link">DockerHub</a> image. For R users see the
<a href="https://rocker-project.org/images/versioned/rstudio.html" class="external-link">rocker
project</a> for some good options. The one used in the example file is
“rocker/r-bspm:jammy” which has is based on ubuntu jammy and has R
installed and set up to use the bspm package so that R packages can be
installed on linux from binary using <code>install.packages</code> as
usual.</li>
</ul>
</div>
<div class="section level4">
<h4 id="optional-customization-fields">Optional customization fields:<a class="anchor" aria-label="anchor" href="#optional-customization-fields"></a>
</h4>
<ul>
<li>imageReference: I have provided two pool template JSON files, one
for windows and one for linux so you can just use one of those unless
you have another reason to customize. (TODO: windows version did not
work with example) This is basically the operating system that you want
to use. You can choose from windows or linux options, but if you want to
use docker you need to choose one that is docker compatible. To do this
you can run
<code>az batch pool supported-images list --filter "osType eq 'linux'"|tee test_linux.txt</code>
this lists the supported images for the linux osType, change to
‘windows’ to see windows options, and outputs the result to a text file.
I then searched the text file for “dockerCompatible”</li>
</ul>
<p>Once you are happy with the JSON file you can create your pool by
running
<code>az batch pool create --json-file cloud_config/template_pool_cli.json</code></p>
<p>Run <code>az batch pool list</code> to see the status of the
pool.</p>
</div>
</div>
<div class="section level3">
<h3 id="create-a-job">Create a job<a class="anchor" aria-label="anchor" href="#create-a-job"></a>
</h3>
<p><code>az batch job create --pool-id test_pool_json_cli --id "test_job"</code></p>
</div>
<div class="section level3">
<h3 id="create-a-task">Create a task<a class="anchor" aria-label="anchor" href="#create-a-task"></a>
</h3>
<p>Similar to creating a pool we create a task by referring to a JSON
configuration file and the job id where the task should be assigned.</p>
<p>The JSON file will depend on the task to be performed.
“template_task_hello.json” reflects the simplest case where there are no
input or output files and it runs an R function directly from the
command line.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"sampleTask"</span><span class="fu">,</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  <span class="dt">"commandLine"</span><span class="fu">:</span> <span class="st">"R -e 'mean(mtcars$mpg)'"</span><span class="fu">,</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    <span class="dt">"containerSettings"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    <span class="dt">"imageName"</span><span class="fu">:</span> <span class="st">"rocker/r-bspm:jammy"</span><span class="fu">,</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    <span class="dt">"containerRunOptions"</span><span class="fu">:</span> <span class="st">"--rm"</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    <span class="fu">},</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>  <span class="dt">"userIdentity"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>      <span class="dt">"autoUser"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>          <span class="dt">"scope"</span><span class="fu">:</span> <span class="st">"task"</span><span class="fu">,</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>          <span class="dt">"elevationLevel"</span><span class="fu">:</span> <span class="st">"nonadmin"</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>      <span class="fu">}</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<p>JSON file fields:</p>
<ul>
<li>id: name of the task</li>
<li>commandLine: command line code to run. In this case because R is
already installed on the docker container this just works.</li>
<li>imageName: The DockerHub image to use</li>
<li>containerRunOptions: options that would normally be supplied with
the <code>docker run</code> command</li>
<li>userIdentity: The identity of the user running the task, scope can
be pool or task and elevationLevel can be admin or nonadmin.</li>
</ul>
<p>The task will start to execute as soon as we create the task.</p>
<pre><code>az batch task create --json-file cloud_config/template_task_hello.json --job-id test_job</code></pre>
<p>We can check the status of the task and filter the output with a
query to only get the information we need.</p>
<pre><code>az batch task show --job-id test_job --task-id sampleTask

az batch task show --job-id test_job --task-id sampleTask --query "{state: state, executionInfo: executionInfo}" --output jsonc</code></pre>
<p>The “state” should be active, running, or completed (active is the
state when the task is starting up) and executionInfo will tell you the
result (success or failure) and start and end time.</p>
<p>To find out more about what is going on in you task you can download
the stdout or stderr files. stdout.txt will show the console output on
the machine and stderr.txt will show any error messages.</p>
<pre><code>az batch task file download --task-id sampleTask --job-id test_job --file-path "stdout.txt" --destination "./run_out.txt"</code></pre>
</div>
<div class="section level3">
<h3 id="clean-up">Clean up<a class="anchor" aria-label="anchor" href="#clean-up"></a>
</h3>
<p><strong>Always remember to delete your pools and jobs when they are
complete</strong>. We will be charged for as long as a pool is up
regardless of whether anything is actually running on it. Tasks are
deleted when the pool they are part of is deleted but jobs need to be
deleted separately.</p>
<p>To delete the pool and job we created and confirm they were deleted
run the following:</p>
<pre><code>az batch job delete --job-id test_job
az batch pool delete --pool-id test_pool_json_cli

az batch job list --query "[].{id:id, state:state}"
az batch pool list --query "[].{id:id, state:state}"</code></pre>
<p>You may need to wait awhile for the pool to finish being deleted.</p>
</div>
</div>
<div class="section level2">
<h2 id="access-data-in-your-task">Access data in your task<a class="anchor" aria-label="anchor" href="#access-data-in-your-task"></a>
</h2>
<p>One thing to keep in mind is that your task has access to the
internet so any method that you could normally use to access data and/or
code over the internet should work in a script as long as you can set it
up to work non-interactively. You might consider storing data on OSF or
google drive or GitHub so that anyone can run your script and have the
data load automatically. Another option that I will demonstrate here is
to load your data onto an Azure Storage Container and connect it to your
task. This uses the azcopy tool that we installed at the beginning in
the background.</p>
<p>To run this example clone this GitHub repo by running
<code>usethis::create_from_github("LandSciTech/cloudDemo")</code> in R.
Then you will have the analyses folder which contains two folders:</p>
<ul>
<li>scripts:
<ul>
<li>script_read_csv.R A super simple R script that reads a csv subsets
the table and saves a new csv</li>
<li>run_script.sh A bash script that runs the R script</li>
</ul>
</li>
<li>data:
<ul>
<li>raw-data:
<ul>
<li>fruits.csv data used by the script</li>
</ul>
</li>
<li>derived-data:
<ul>
<li>just has a README for now but is where results are stored.</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="section level3">
<h3 id="upload-files-to-container">Upload files to container<a class="anchor" aria-label="anchor" href="#upload-files-to-container"></a>
</h3>
<p>If you don’t have an existing container under your name in the Azure
storage account create one using your first initial and last name.</p>
<pre><code>az storage container create --name jdoe --account-name ecdcwls --auth-mode login</code></pre>
<p>Next, get a Shared Access Token for the container you want to access
by running the below replacing “sendicott” with the name of your own
storage container. This will save it as a variable
<code>sastoken</code>, the token will expire after one day, in most real
use cases I would change the expiry to as long as you expect the
analysis to run. The <code>sasurl</code> is the full url for the
container with the SAS token included and can be used as a single
argument in some cases.</p>
<pre><code>end=`date -u -d "1 day" '+%Y-%m-%dT%H:%MZ'`

sastoken=`az storage container generate-sas --account-name ecdcwls --expiry $end --name sendicott --permissions racwdli -o tsv --auth-mode login --as-user`

sasurl=https://ecdcwls.blob.core.windows.net/sendicott/?$sastoken</code></pre>
<p>Then copy all files from a local directory to the container url
created above then list the filenames in the container.</p>
<pre><code>az storage copy -d $sasurl -s analyses --recursive

az storage blob list -c sendicott --account-name ecdcwls --sas-token $sastoken --query "[].{name:name}"</code></pre>
</div>
<div class="section level3">
<h3 id="connect-container-to-task">Connect container to task<a class="anchor" aria-label="anchor" href="#connect-container-to-task"></a>
</h3>
<p>To access files in the container from the task we can modify the
simple JSON above to add some additional options.</p>
<p>The “outputFiles” option lets you link the container as the place
where output files will be stored. Use “path” to set the location within
the container where you want the file to be saved. Under filePattern
select the file to save, either with a path to a specific file or a
pattern to match multiple files. Note that the file upload only occurs
when the task completes so if the task ends without completing no files
will be saved.</p>
<p>Below I have defined two “outputFiles” one to save the results
created in derived-data and one to store the stdout.txt and stderr.txt
files that show the console output and error output. The stdout files
are located above the working directory of the task which is why we need
“../”</p>
<p>Adding the input files is much simpler, in this case you just need to
supply the name of the container to the autoStorageContainerName option.
All the files in the container will be copied into the working directory
of the task.</p>
<p>In addition, I have changed the commandLine to run the bash script
stored in the scripts folder. The bash script is not necessary in this
simple example but is useful if you want to run multiple scripts or do
anything else from the commandLine before running a script.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"test_outFile"</span><span class="fu">,</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>  <span class="dt">"commandLine"</span><span class="fu">:</span> <span class="st">"sh analyses/scripts/run_script.sh"</span><span class="fu">,</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>  <span class="dt">"resourceFiles"</span><span class="fu">:</span> <span class="ot">[</span><span class="fu">{</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>        <span class="dt">"autoStorageContainerName"</span><span class="fu">:</span> <span class="st">"sendicott"</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    <span class="ot">]</span><span class="fu">,</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>  <span class="dt">"outputFiles"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    <span class="dt">"destination"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>            <span class="dt">"container"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>                <span class="dt">"containerUrl"</span><span class="fu">:</span> <span class="st">"https://ecdcwls.blob.core.windows.net/sendicott/?&lt;sastoken&gt;"</span><span class="fu">,</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>                <span class="dt">"path"</span><span class="fu">:</span> <span class="st">"logs"</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>            <span class="fu">}</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>        <span class="fu">},</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>        <span class="dt">"filePattern"</span><span class="fu">:</span> <span class="st">"../std*.txt"</span><span class="fu">,</span></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>        <span class="dt">"uploadOptions"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>            <span class="dt">"uploadCondition"</span><span class="fu">:</span> <span class="st">"taskcompletion"</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>        <span class="fu">}</span></span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>    <span class="fu">}</span><span class="ot">,</span></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>        <span class="dt">"destination"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>            <span class="dt">"container"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>                <span class="dt">"containerUrl"</span><span class="fu">:</span> <span class="st">"https://ecdcwls.blob.core.windows.net/sendicott/?&lt;sastoken&gt;"</span><span class="fu">,</span></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>                <span class="dt">"path"</span><span class="fu">:</span> <span class="st">"analyses/data/derived-data/output_price2.csv"</span></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>            <span class="fu">}</span></span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>        <span class="fu">},</span></span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>        <span class="dt">"filePattern"</span><span class="fu">:</span> <span class="st">"analyses/data/derived-data/output_price2.csv"</span><span class="fu">,</span></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>        <span class="dt">"uploadOptions"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>            <span class="dt">"uploadCondition"</span><span class="fu">:</span> <span class="st">"taskcompletion"</span></span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>        <span class="fu">}</span></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>    <span class="ot">]</span><span class="fu">,</span></span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>    <span class="dt">"containerSettings"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>        <span class="dt">"imageName"</span><span class="fu">:</span> <span class="st">"rocker/r-ubuntu:jammy"</span><span class="fu">,</span></span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>        <span class="dt">"containerRunOptions"</span><span class="fu">:</span> <span class="st">"--rm"</span></span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a>    <span class="fu">},</span></span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>    <span class="dt">"userIdentity"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>        <span class="dt">"autoUser"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>            <span class="dt">"scope"</span><span class="fu">:</span> <span class="st">"task"</span><span class="fu">,</span></span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a>            <span class="dt">"elevationLevel"</span><span class="fu">:</span> <span class="st">"admin"</span></span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>        <span class="fu">}</span></span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<p>Next we need to replace the <code>&lt;sastoken&gt;</code> placeholder
in the template with the value of the <code>sastoken</code> variable we
created above and save the resulting file. We do this to avoid saving
the sastoken in the template script so it won’t accidentally get shared
with others. We can delete the script with the file once we launch the
task since it is easy to recreate it when needed.</p>
<pre><code>sed 's/&lt;sastoken&gt;/'${sastoken//&amp;/\\&amp;}'/g' cloud_config/template_task_with_file_in_out.json &gt; cloud_config/task_to_use.json</code></pre>
<p>Follow the same process as above to create a pool, job and task, this
time with our new JSON file. Then delete the modified JSON file that
contains the sastoken</p>
<pre><code>az batch pool create --json-file cloud_config/template_pool_cli.json
az batch job create --pool-id test_pool_json_cli --id "test_job"
az batch task create --json-file cloud_config/task_to_use.json --job-id test_job

rm cloud_config/task_to_use.json</code></pre>
<p>Check the task status and confirm that files have been uploaded to
the container</p>
<pre><code>az batch task show --job-id test_job --task-id test_outFile --query "{state: state, executionInfo: executionInfo}" --output jsonc

az storage blob list -c sendicott --account-name ecdcwls --sas-token $sastoken --query "[].{name:name}"</code></pre>
<p>Download the files that you want to save locally.</p>
<pre><code>az storage copy -s https://ecdcwls.blob.core.windows.net/sendicott/analyses/data/derived-data?$sastoken -d analyses/data --recursive</code></pre>
<p>Delete the analyses folder from your container to remove all the
files. This doesn’t have to happen right away but I try not to leave
things here since we have other long term storage solutions and I don’t
want to clutter the container.</p>
<pre><code>az storage remove -c sendicott --account-name ecdcwls --sas-token $sastoken -n analyses --recursive</code></pre>
<p>To delete all files in the container don’t supply a name argument</p>
<pre><code>az storage remove -c sendicott --account-name ecdcwls --sas-token $sastoken  --recursive</code></pre>
<p>Delete the job and pool so that we are no longer charged. Note after
you do this the local copy on your machine is the only copy of the files
from the analysis.</p>
<pre><code>az batch job delete --job-id test_job
az batch pool delete --pool-id test_pool_json_cli

az batch job list --query "[].{id:id, state:state}"
az batch pool list --query "[].{id:id, state:state}"</code></pre>
</div>
</div>
<div class="section level2">
<h2 id="install-azcopy-if-needed">Install AzCopy if needed<a class="anchor" aria-label="anchor" href="#install-azcopy-if-needed"></a>
</h2>
<p>AzCopy is another command line tool that is used by the az storage
commands above. It should automatically be installed the first time you
run one of them but if not here are the instructions for downloading
it.</p>
<ol style="list-style-type: decimal">
<li>Download azcopy <a href="https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10" class="external-link uri">https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10</a>
</li>
<li>Unzip into an easy to access directory ie C:\ or C:\Users\username
you will need to navigate the command line to this directory to run
commands unless you <a href="https://www.howtogeek.com/118594/how-to-edit-your-system-path-for-easy-command-line-access/" class="external-link">add
azcopy to your PATH</a>.</li>
</ol>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sarah Endicott.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
