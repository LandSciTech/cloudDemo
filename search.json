[{"path":"https://landscitech.github.io/cloudDemo/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 2, June 1991Copyright © 1989, 1991 Free Software Foundation, Inc.,51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://landscitech.github.io/cloudDemo/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"licenses software designed take away freedom share change . contrast, GNU General Public License intended guarantee freedom share change free software–make sure software free users. General Public License applies Free Software Foundation’s software program whose authors commit using . (Free Software Foundation software covered GNU Lesser General Public License instead.) can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge service wish), receive source code can get want , can change software use pieces new free programs; know can things. protect rights, need make restrictions forbid anyone deny rights ask surrender rights. restrictions translate certain responsibilities distribute copies software, modify . example, distribute copies program, whether gratis fee, must give recipients rights . must make sure , , receive can get source code. must show terms know rights. protect rights two steps: (1) copyright software, (2) offer license gives legal permission copy, distribute /modify software. Also, author’s protection , want make certain everyone understands warranty free software. software modified someone else passed , want recipients know original, problems introduced others reflect original authors’ reputations. Finally, free program threatened constantly software patents. wish avoid danger redistributors free program individually obtain patent licenses, effect making program proprietary. prevent , made clear patent must licensed everyone’s free use licensed . precise terms conditions copying, distribution modification follow.","code":""},{"path":"https://landscitech.github.io/cloudDemo/LICENSE.html","id":"terms-and-conditions-for-copying-distribution-and-modification","dir":"","previous_headings":"","what":"TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION","title":"GNU General Public License","text":"0. License applies program work contains notice placed copyright holder saying may distributed terms General Public License. “Program”, , refers program work, “work based Program” means either Program derivative work copyright law: say, work containing Program portion , either verbatim modifications /translated another language. (Hereinafter, translation included without limitation term “modification”.) licensee addressed “”. Activities copying, distribution modification covered License; outside scope. act running Program restricted, output Program covered contents constitute work based Program (independent made running Program). Whether true depends Program . 1. may copy distribute verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice disclaimer warranty; keep intact notices refer License absence warranty; give recipients Program copy License along Program. may charge fee physical act transferring copy, may option offer warranty protection exchange fee. 2. may modify copy copies Program portion , thus forming work based Program, copy distribute modifications work terms Section 1 , provided also meet conditions: ) must cause modified files carry prominent notices stating changed files date change. b) must cause work distribute publish, whole part contains derived Program part thereof, licensed whole charge third parties terms License. c) modified program normally reads commands interactively run, must cause , started running interactive use ordinary way, print display announcement including appropriate copyright notice notice warranty (else, saying provide warranty) users may redistribute program conditions, telling user view copy License. (Exception: Program interactive normally print announcement, work based Program required print announcement.) requirements apply modified work whole. identifiable sections work derived Program, can reasonably considered independent separate works , License, terms, apply sections distribute separate works. distribute sections part whole work based Program, distribution whole must terms License, whose permissions licensees extend entire whole, thus every part regardless wrote . Thus, intent section claim rights contest rights work written entirely ; rather, intent exercise right control distribution derivative collective works based Program. addition, mere aggregation another work based Program Program (work based Program) volume storage distribution medium bring work scope License. 3. may copy distribute Program (work based , Section 2) object code executable form terms Sections 1 2 provided also one following: ) Accompany complete corresponding machine-readable source code, must distributed terms Sections 1 2 medium customarily used software interchange; , b) Accompany written offer, valid least three years, give third party, charge cost physically performing source distribution, complete machine-readable copy corresponding source code, distributed terms Sections 1 2 medium customarily used software interchange; , c) Accompany information received offer distribute corresponding source code. (alternative allowed noncommercial distribution received program object code executable form offer, accord Subsection b .) source code work means preferred form work making modifications . executable work, complete source code means source code modules contains, plus associated interface definition files, plus scripts used control compilation installation executable. However, special exception, source code distributed need include anything normally distributed (either source binary form) major components (compiler, kernel, ) operating system executable runs, unless component accompanies executable. distribution executable object code made offering access copy designated place, offering equivalent access copy source code place counts distribution source code, even though third parties compelled copy source along object code. 4. may copy, modify, sublicense, distribute Program except expressly provided License. attempt otherwise copy, modify, sublicense distribute Program void, automatically terminate rights License. However, parties received copies, rights, License licenses terminated long parties remain full compliance. 5. required accept License, since signed . However, nothing else grants permission modify distribute Program derivative works. actions prohibited law accept License. Therefore, modifying distributing Program (work based Program), indicate acceptance License , terms conditions copying, distributing modifying Program works based . 6. time redistribute Program (work based Program), recipient automatically receives license original licensor copy, distribute modify Program subject terms conditions. may impose restrictions recipients’ exercise rights granted herein. responsible enforcing compliance third parties License. 7. , consequence court judgment allegation patent infringement reason (limited patent issues), conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. distribute satisfy simultaneously obligations License pertinent obligations, consequence may distribute Program . example, patent license permit royalty-free redistribution Program receive copies directly indirectly , way satisfy License refrain entirely distribution Program. portion section held invalid unenforceable particular circumstance, balance section intended apply section whole intended apply circumstances. purpose section induce infringe patents property right claims contest validity claims; section sole purpose protecting integrity free software distribution system, implemented public license practices. Many people made generous contributions wide range software distributed system reliance consistent application system; author/donor decide willing distribute software system licensee impose choice. section intended make thoroughly clear believed consequence rest License. 8. distribution /use Program restricted certain countries either patents copyrighted interfaces, original copyright holder places Program License may add explicit geographical distribution limitation excluding countries, distribution permitted among countries thus excluded. case, License incorporates limitation written body License. 9. Free Software Foundation may publish revised /new versions General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies version number License applies “later version”, option following terms conditions either version later version published Free Software Foundation. Program specify version number License, may choose version ever published Free Software Foundation. 10. wish incorporate parts Program free programs whose distribution conditions different, write author ask permission. software copyrighted Free Software Foundation, write Free Software Foundation; sometimes make exceptions . decision guided two goals preserving free status derivatives free software promoting sharing reuse software generally.","code":""},{"path":"https://landscitech.github.io/cloudDemo/LICENSE.html","id":"no-warranty","dir":"","previous_headings":"","what":"NO WARRANTY","title":"GNU General Public License","text":"11. PROGRAM LICENSED FREE CHARGE, WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION. 12. EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MAY MODIFY /REDISTRIBUTE PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES. END TERMS CONDITIONS","code":""},{"path":"https://landscitech.github.io/cloudDemo/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively convey exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program interactive, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, commands use may called something show w show c; even mouse-clicks menu items–whatever suits program. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. sample; alter names: General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details. Yoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker.  <signature of Ty Coon>, 1 April 1989 Ty Coon, President of Vice"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"microsoft-help-pages","dir":"Articles","previous_headings":"","what":"Microsoft help pages","title":"Useful Azure CLI commands","text":"lot info figured things much little overwhelming. Onboarding cheat sheet Reference index Z","code":""},{"path":[]},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"list-pools","dir":"Articles","previous_headings":"Useful commands","what":"List pools","title":"Useful Azure CLI commands","text":"az batch pool list returns info every pool. can use --query simplify . query returns id information numbers nodes pools. also changed --output default json table since compact. query output global parameters available functions. break query, first [] means going get values element array. part {} chooses properties return display names . JMESPath querys can powerful. See help page details. example, can also add filter query:","code":"az batch pool list \\ --query \"[].{name:id, vmSize:vmSize,  curNodes: currentDedicatedNodes,tarNodes: targetDedicatedN odes, allocState:allocationState}\" \\ --output table  #> Name             VmSize          CurNodes    TarNodes    AllocState #> ---------------  --------------  ----------  ----------  ------------ #> amartin_pool4    standard_d8_v3  1           1           steady #> amartin_pool5    standard_d8_v3  1           1           steady #> amartin_pool6    standard_d8_v3  1           1           steady #> sendicott_roads  standard_e2_v3  1           0           resizing az batch pool list \\ --query \"[?id == 'sendicott_roads'].{name:id, vmSize:vmSize,  curNodes: currentDedicatedNodes,tarNodes: targetDedicatedNodes, allocState:allocationState}\" \\ --output table #> Name             VmSize          CurNodes    TarNodes    AllocState #> ---------------  --------------  ----------  ----------  ------------ #> sendicott_roads  standard_e2_v3  1           0           resizing   az batch pool list \\ --query \"[?contains(id, 'amartin')].{name:id, vmSize:vmSize,  curNodes:currentDedicatedNodes,tarNodes: targetDedicatedNodes, allocState:allocationState}\" \\ --output table #> Name            VmSize          CurNodes    TarNodes    AllocState #> ----------      --------------  ----------  ----------  ------------ #> amartin_pool4   standard_d8_v3  1           1           steady #> amartin_pool5   standard_d8_v3  1           1           steady #> amartin_pool6   standard_d8_v3  1           1           steady"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"get-subnet-id-for-use-in-json-pool-files","dir":"Articles","previous_headings":"Useful commands","what":"Get subnet id for use in JSON pool files","title":"Useful Azure CLI commands","text":"can also save output query variable use future commands","code":"subnetid=$(az network vnet subnet list --resource-group EcDc-WLS-rg --vnet-name EcDc-WLS-vnet \\ --query \"[?name=='EcDc-WLS_compute-cluster-snet'].id\" --output tsv)"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"get-sastoken-and-sasurl","dir":"Articles","previous_headings":"Useful commands","what":"Get sastoken and sasurl","title":"Useful Azure CLI commands","text":"","code":"# 7 days seems to be the max that the cli will allow end=`date -u -d \"7 days\" '+%Y-%m-%dT%H:%MZ'` sastoken=`az storage container generate-sas --account-name ecdcwls --expiry $end --name sendicott --permissions racwdli -o tsv --auth-mode login --as-user`  sasurl=https://ecdcwls.blob.core.windows.net/sendicott/?$sastoken"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"list-files-in-storage-container","dir":"Articles","previous_headings":"Useful commands","what":"List files in storage container","title":"Useful Azure CLI commands","text":"","code":"az storage blob list -c sendicott --account-name ecdcwls --sas-token $sastoken \\ --query \"[].{name:name}\" --output yaml"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"copy-file-to-storage","dir":"Articles","previous_headings":"Useful commands","what":"Copy file to storage","title":"Useful Azure CLI commands","text":"","code":"sasurl=https://ecdcwls.blob.core.windows.net/sendicott/?$sastoken  az storage copy -d $sasurl -s analyses/scripts/run_script.sh"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"copy-folder-to-storage","dir":"Articles","previous_headings":"Useful commands","what":"Copy folder to storage","title":"Useful Azure CLI commands","text":"copy individual files end root storage container, copy folder using --recursize folder structure reflected storage container. copy contents folder using wildcard (path//folder/*) copy file root container.","code":"az storage copy -d $sasurl -s analyses/scripts --recursive az storage copy -d $sasurl -s \"analyses/scripts/*\""},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"copydownload-files-from-storage","dir":"Articles","previous_headings":"Useful commands","what":"Copy/download files from storage","title":"Useful Azure CLI commands","text":"can download files using pattern. download files sendicott container end “.R” save new folder called scripts2 adding folder name container name ?$sastoken: Using recursive copy folder contents: using folder name followed * just copy file","code":"az storage copy -s https://ecdcwls.blob.core.windows.net/sendicott/*?$sastoken \\ -d \"analyses/scripts2\" --include-pattern \"*.R\" az storage copy -s https://ecdcwls.blob.core.windows.net/sendicott/scripts?$sastoken \\ -d \"analyses/scripts3\" --recursive az storage copy -s https://ecdcwls.blob.core.windows.net/sendicott/scripts/*?$sastoken \\ -d \"analyses/scripts4\""},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"delete-files-on-storage","dir":"Articles","previous_headings":"Useful commands","what":"Delete files on storage","title":"Useful Azure CLI commands","text":"Remove files matching pattern: Delete one folder Delete everything container Note can also exclude files matching pattern e.g. --exclude-pattern \"*.gpkg\".","code":"az storage remove -c sendicott --include-pattern \"*.rds\" --account-name ecdcwls --sas-token $sastoken --recursive az storage remove -c sendicott -n scripts --account-name ecdcwls \\ --sas-token $sastoken --recursive az storage remove -c sendicott --account-name ecdcwls \\ --sas-token $sastoken --recursive"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"create-pool-job-task","dir":"Articles","previous_headings":"Useful commands","what":"Create pool, job, task","title":"Useful Azure CLI commands","text":"create many tasks loop. assumes created may different task jsons different files numbered.","code":"poolName=\"test_pool_json_cli\" jobName=\"sendicott_job_test\"  az batch pool create --json-file cloud_config/template_pool_cli.json az batch job create --pool-id $poolName --id $jobName az batch task create --json-file cloud_config/template_task_hello.json --job-id $jobName for rowi in {1..27} do   az batch task create --json-file analysis/cloud/task_jsons/task_roads_$rowi.json --job-id $jobName done"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"reactivate-task","dir":"Articles","previous_headings":"Useful commands","what":"Reactivate task","title":"Useful Azure CLI commands","text":"re-run task failed. Useful fixed one scripts re-uploaded error stochastic thing want try . Won’t re-run successful tasks","code":"az batch task reactivate --job-id $jobName --task-id sampleTask"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"delete-pool-job-task","dir":"Articles","previous_headings":"Useful commands","what":"Delete Pool, job, task","title":"Useful Azure CLI commands","text":"","code":"# you will have to confirm in the console or add --yes az batch job delete --job-id $jobName az batch pool delete --pool-id $poolName  # if you delete the pool the task is deleted anyway az batch task delete --task-id sampleTask --job-id $jobName --yes"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"monitoring-tasks","dir":"Articles","previous_headings":"Useful commands","what":"Monitoring tasks","title":"Useful Azure CLI commands","text":"","code":"# details for a single task filtered by query az batch task show --job-id $jobName --task-id sampleTask \\ --query \"{state: state, executionInfo: executionInfo}\" --output yaml  # Summary of state for all tasks in job az batch job task-counts show --job-id $jobName  # Get other info from multiple tasks az batch task list --job-id $jobName \\ --query \"{tasks: [].[id, executionInfo.{st:startTime, end:endTime}][]}\" --output yaml"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"download-output-file-from-a-task","dir":"Articles","previous_headings":"Useful commands","what":"Download output file from a task","title":"Useful Azure CLI commands","text":"","code":"az batch task file download --task-id sampleTask --job-id $jobName \\ --file-path \"stdout.txt\" --destination \"cloud_config/stdout.txt\"  # print the file to console cat \"cloud_config/stdout.txt\"  # or print the last n lines  tail \"cloud_config/stdout.txt\" -n 5"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"manage-nodes-in-pool","dir":"Articles","previous_headings":"Useful commands","what":"Manage nodes in pool","title":"Useful Azure CLI commands","text":"running many tasks pool usually start one node, check working resize desired number nodes.","code":"# set target dedicated nodes az batch pool resize --pool-id $poolName --target-dedicated-nodes 3  # check pool node counts az batch pool list  \\ --query \"[?id=='\"$poolName\"'].{curNodes: currentDedicatedNodes,tarNodes: targetDedicatedNodes, allocState:allocationState}\" \\ --output yaml  # check node state az batch node list --pool-id $poolName --query \"{nodes: [].[id, state][]}\" --output json"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"enable-autoscaling","dir":"Articles","previous_headings":"Useful commands","what":"Enable autoscaling","title":"Useful Azure CLI commands","text":"pool running well confident results saved expected enable autoscaling charged task finished running. mean task deleted completes won’t able look logs files afterwards. See example autoscaling workflow One confusing aspect autoscaling doesn’t happen immediately interval set shortest available means run every 5 minutes. generally seems like working, wait 5 mins check . formula hard read, documentation available try explain logic example. First set max VMs 25 since account max 27, may want set lower others using account time. Next find many tasks currently waiting (“active tasks”) many currently running. Unfortunately simple number values exactly accurate real time, recorded every 30s sometimes process fails value missing. Therefore recommendation use sampling values, case chosen last 2 minutes returns vector values recorded last 2 minutes. take max values add current active tasks together get total number tasks want run. determine number nodes currently available. use max current target nodes think 0 nodes pool still starting target 0 new tasks added. Next determine total number tasks can run time (called cores ). calculate number additional nodes needed given total number tasks minus existing number cores number task slots per node. set target dedicated nodes making sure 0 25. Finally, set node deallocation option tasks running node must finish shutdown. Although autoscaling runs every 5 minutes can check result evaluating autoscaling formula. works autoscaling enabled. autoscaling working desired want change formula can disable autoscaling manually set number nodes needed. make sure turn autoscaling back tasks started ensure pool keep running tasks complete.","code":"# you can prompt autoscaling of pool by changing time interval az batch pool autoscale enable --pool-id $poolName --auto-scale-evaluation-interval \"PT5M\"\\  --auto-scale-formula 'maxNumberofVMs = 25;  $atasks = $ActiveTasks.GetSample(TimeInterval_Minute * 2, 1);  $rtasks = $RunningTasks.GetSample(TimeInterval_Minute * 2, 1);  $tasks = max($atasks) + max($rtasks);  $nodes = max($CurrentDedicatedNodes, $TargetDedicatedNodes);  $cores = $nodes*$TaskSlotsPerNode;  $extraVMs = ceil((($tasks - $cores) + 0) / $TaskSlotsPerNode);  $targetVMs = ($nodes + $extraVMs);  $TargetDedicatedNodes = max(0, min($targetVMs, maxNumberofVMs));  $NodeDeallocationOption = taskcompletion;' # This will show what the formula would return if autoscaling ran now.   az batch pool autoscale evaluate --pool-id $poolName \\ --auto-scale-formula 'maxNumberofVMs = 25;  $atasks = $ActiveTasks.GetSample(TimeInterval_Minute * 2, 1);  $rtasks = $RunningTasks.GetSample(TimeInterval_Minute * 2, 1);  $tasks = max($atasks) + max($rtasks);  $nodes = max($CurrentDedicatedNodes, $TargetDedicatedNodes);  $cores = $nodes*$TaskSlotsPerNode;  $extraVMs = ceil((($tasks - $cores) + 0) / $TaskSlotsPerNode);  $targetVMs = ($nodes + $extraVMs);  $TargetDedicatedNodes = max(0, min($targetVMs, maxNumberofVMs));  $NodeDeallocationOption = taskcompletion;' az batch pool autoscale disable --pool-id $poolName az batch pool resize --pool-id $poolName --target-dedicated-nodes 12"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"monitor-cpu-usage-and-memory","dir":"Articles","previous_headings":"Useful commands","what":"Monitor CPU usage and memory","title":"Useful Azure CLI commands","text":"check CPU usage memory usage node can run additional task node setting multiple taskSlotsPerNode. Follow script set monitoring task produce graph memory usage based values returned.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"get-github-pat-token","dir":"Articles","previous_headings":"Useful commands","what":"Get GitHub PAT token","title":"Useful Azure CLI commands","text":"Get GitHub PAT within bash supply script programatically avoid saving files might accidentally get shared. Use sed described replace placeholder script token can add *_to_use* .gitignore file avoid scripts accidentally ending GitHUb. R script following line placeholder set environment variable allow packages install without warnings GitHub API limit.","code":"ghpat=`Rscript -e \"cat(gh::gh_token())\"` sed 's,<pat>,'$ghpat',g' make.R > make_to_use.R Sys.setenv(GITHUB_PAT = \"<pat>\")"},{"path":"https://landscitech.github.io/cloudDemo/articles/cliCommands.html","id":"use-sed-to-replace-placeholder-text-in-files","dir":"Articles","previous_headings":"Useful commands","what":"Use sed to replace placeholder text in files","title":"Useful Azure CLI commands","text":"sed command line tool allows replace placeholder text file value generated script example using sastoken created : important avoid hard coding secret passwords tokens saved files. remove “to_use” file contains password done (rm cloud_config/task_to_use.json). can also add *to_use* .gitignore file make sure don’t accidentally get added GitHub. syntax sed bit tricky complicated special characters sastoken. command s indicates want use seds subsitiution command, comma (,) delimiter shows start string replaced. “<sastoken>” text replaced (<> doesn’t special meaning just convention placeholders). second comma shows start string replace . $ means part inside {} evaluated first part sed command. //&/\\\\& just add \\ & sastoken don’t get interpreted special characters sed. third comma shows end text replace g indicates every instance pattern replaced. Finally first path template file containing placeholder second path file create. / default delimiter used sed doesn’t work slashes replacement text used commas instead. See sed documentation details examples. can also use sed loop create many different versions file: first replaces <SASURL> file uses pipe | pass result another sed command replaces <row> loop index rowi saves file row appended. can helpful creating many different versions task.","code":"sed 's,<sastoken>,'${sastoken//&/\\\\&}',g' cloud_config/template_task_with_file_in_out.json > cloud_config/task_to_use.json for rowi in {1..27} do   sed 's,<SASURL>,'${sasurl//&/\\\\&}',g' analysis/cloud/task_roads.json\\   | sed 's,<row>,'$rowi',g' > analysis/cloud/task_jsons/task_roads_$rowi.json done"},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Setting up cloud processing with Azure Batch","text":"Azure Batch one many Azure services can used run analyses cloud. uses hierarchy Pools contain Jobs contain Tasks. Pool group Nodes (similar virtual machines) computers run analyses. pool created choose number nodes configure operating system, RAM number cores node . Jobs used scheduling different related tasks, simple cases just folder contains tasks. Tasks contain code want node run information get data save . several options available interacting Azure Batch including Azure web portal Azure command line interface (CLI). tutorial focus Azure CLI method since simplest fastest method. cases need ECCC network access cloud, either office VPN. Azure CLI can used terminal Windows code written assuming using Bash Terminal run exactly written terminals.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"get-access","dir":"Articles","previous_headings":"","what":"Get Access","title":"Setting up cloud processing with Azure Batch","text":"added LERS Azure Batch account email Sarah Endicott, email CCOE (Cloud Centre Expertise) ask give account required permissions. recommend allowing week process.","code":""},{"path":[]},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"azure-cli","dir":"Articles","previous_headings":"Install Azure CLI","what":"Azure CLI","title":"Setting up cloud processing with Azure Batch","text":"Install using install wizard https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-windows?tabs=azure-cli#install--update don’t elevated privileges need call service desk complete installation .","code":""},{"path":[]},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"sign-in","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis","what":"Sign in","title":"Setting up cloud processing with Azure Batch","text":"Run az login terminal. open web browser login. Run az batch account login -g EcDc-WLS-rg -n ecdcwlsbatch connect “EcDc-WLS-rg” resource group “ecdcwlsbatch” service name. Run az batch pool list show existing pools. Note: get error point saying “request authorized perform operation.” likely signed VPN, sign try .","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"create-a-pool","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis","what":"Create a pool","title":"Setting up cloud processing with Azure Batch","text":"can create pool CLI either providing configuration individual arguments supplying JSON file. use JSON file option easy modify previous versions functionality available argument. template JSON file provided repository cloud_config/template_pool_cli.json. parts JSON file stay cases others need adjusted based type pool want build.","code":"{     \"type\": \"Microsoft.Batch/batchAccounts/pools\",     \"apiVersion\": \"2016-12-01\",     \"id\": \"test_pool_json_cli\",     \"vmSize\": \"standard_DS2_v2\",     \"virtualMachineConfiguration\": {         \"imageReference\": {             \"publisher\": null,             \"offer\": null,             \"sku\": null,             \"version\": null,             \"virtualMachineImageId\": \"/subscriptions/b215566c-fe84-4c8f-a24c-99de0b444b13/resourceGroups/EcPc-SharedImageGallery-rg/providers/Microsoft.Compute/galleries/EcPcSharedImageGallery/images/Ubuntu2404WithDocker/versions/1.0.0\",             \"exactVersion\": null         },         \"nodeAgentSKUId\": \"batch.node.ubuntu 24.04\",         \"licenseType\": null,         \"containerConfiguration\": {             \"type\": \"dockerCompatible\",             \"containerImageNames\": [                 \"rocker/r-bspm:jammy\"             ]         },         \"nodePlacementConfiguration\": {             \"policy\": \"regional\"         }     },         \"targetDedicatedNodes\": 1,     \"networkConfiguration\": {         \"subnetId\":\"/subscriptions/8bc16bb2-5633-480b-8f4c-3ba6a6c769b4/resourceGroups/EcDc-WLS-rg/providers/Microsoft.Network/virtualNetworks/EcDc-WLS-vnet/subnets/EcDc-WLS_compute-cluster-snet\"         } }"},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"fields-to-edit","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis > Create a pool","what":"Fields to edit:","title":"Setting up cloud processing with Azure Batch","text":"id: Give pool name. start first letter first name last name can differentiate track billing eg “sendicott_test_pool” vmSize: family VM number CPUs, different families different # CPU RAM ratios. access subset VM families quota one. See Microsoft website details different families. easiest way filter options choose size go Azure portal > Batch > Pools page click “Add” scroll vmSize follow link “View full pricing details”. example use “Standard_DS2_v2”. names start “Standard_” substitute sku contains Family, # CPUs version. targetDedicatedNodes: number nodes pool. Typically 1 going run one task might use multiple cores one machine parallelization one task want run separate machine. containerImageNames: name docker image want use. pre-fetch docker image use tasks. can enter name DockerHub image. R users see rocker project good options. one used example file “rocker/r-bspm:jammy” based ubuntu jammy R installed set use bspm package R packages can installed linux binary using install.packages usual.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"optional-customization-fields","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis > Create a pool","what":"Optional customization fields:","title":"Setting up cloud processing with Azure Batch","text":"imageReference: provided two pool template JSON files, one windows one linux can just use one unless another reason customize. basically operating system want use. can choose windows linux options, want use docker need choose one docker compatible. can run az batch pool supported-images list --filter \"osType eq 'linux'\"|tee test_linux.txt lists supported images linux osType, change ‘windows’ see windows options, outputs result text file. searched text file “dockerCompatible”. Azure longer making dockerCompatible images current image used template created CCOE provided Shared Image Gallery. just Ubuntu Docker installed. happy JSON file can create pool running az batch pool create --json-file cloud_config/template_pool_cli.json Run az batch pool list see status pool.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"create-a-job","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis","what":"Create a job","title":"Setting up cloud processing with Azure Batch","text":"az batch job create --pool-id test_pool_json_cli --id \"test_job\"","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"create-a-task","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis","what":"Create a task","title":"Setting up cloud processing with Azure Batch","text":"Similar creating pool create task referring JSON configuration file job id task assigned. JSON file depend task performed. “template_task_hello.json” reflects simplest case input output files runs R function directly command line. JSON file fields: id: name task commandLine: command line code run. case R already installed docker container just works. imageName: DockerHub image use containerRunOptions: options normally supplied docker run command userIdentity: identity user running task, scope can pool task elevationLevel can admin nonadmin. task start execute soon create task. can check status task filter output query get information need. “state” active, running, completed (active state task starting ) executionInfo tell result (success failure) start end time. find going task can download stdout stderr files. stdout.txt show console output machine stderr.txt show error messages.","code":"{   \"id\": \"sampleTask\",   \"commandLine\": \"R -e 'mean(mtcars$mpg)'\",     \"containerSettings\": {     \"imageName\": \"rocker/r-bspm:jammy\",     \"containerRunOptions\": \"--rm\"     },   \"userIdentity\": {       \"autoUser\": {           \"scope\": \"task\",           \"elevationLevel\": \"nonadmin\"       }   } } az batch task create --json-file cloud_config/template_task_hello.json --job-id test_job az batch task show --job-id test_job --task-id sampleTask  az batch task show --job-id test_job --task-id sampleTask --query \"{state: state, executionInfo: executionInfo}\" --output jsonc az batch task file download --task-id sampleTask --job-id test_job --file-path \"stdout.txt\" --destination \"./run_out.txt\""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"clean-up","dir":"Articles","previous_headings":"Use Azure CLI to run an analysis","what":"Clean up","title":"Setting up cloud processing with Azure Batch","text":"Always remember delete pools jobs complete. charged long pool regardless whether anything actually running . Tasks deleted pool part deleted jobs need deleted separately. delete pool job created confirm deleted run following: may need wait awhile pool finish deleted.","code":"az batch job delete --job-id test_job az batch pool delete --pool-id test_pool_json_cli  az batch job list --query \"[].{id:id, state:state}\" az batch pool list --query \"[].{id:id, state:state}\""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"access-data-in-your-task","dir":"Articles","previous_headings":"","what":"Access data in your task","title":"Setting up cloud processing with Azure Batch","text":"One thing keep mind task access internet method normally use access data /code internet work script long can set work non-interactively. might consider storing data OSF google drive GitHub anyone can run script data load automatically. Another option demonstrate load data onto Azure Storage Container connect task. uses azcopy tool installed beginning background. run example clone GitHub repo running usethis::create_from_github(\"LandSciTech/cloudDemo\") R. analyses folder contains two folders: script_read_csv.R super simple R script reads csv subsets table saves new csv run_script.sh bash script runs R script fruits.csv data used script just README now results stored.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"upload-files-to-container","dir":"Articles","previous_headings":"Access data in your task","what":"Upload files to container","title":"Setting up cloud processing with Azure Batch","text":"don’t existing container name Azure storage account create one using first initial last name. Next, get Shared Access Token container want access running replacing “sendicott” name storage container. save variable sastoken, token expire one day, real use cases change expiry long expect analysis run. sasurl full url container SAS token included can used single argument cases. copy files local directory container url created list filenames container.","code":"az storage container create --name jdoe --account-name ecdcwls --auth-mode login end=`date -u -d \"1 day\" '+%Y-%m-%dT%H:%MZ'`  sastoken=`az storage container generate-sas --account-name ecdcwls --expiry $end --name sendicott --permissions racwdli -o tsv --auth-mode login --as-user`  sasurl=https://ecdcwls.blob.core.windows.net/sendicott/?$sastoken az storage copy -d $sasurl -s analyses --recursive  az storage blob list -c sendicott --account-name ecdcwls --sas-token $sastoken --query \"[].{name:name}\""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"connect-container-to-task","dir":"Articles","previous_headings":"Access data in your task","what":"Connect container to task","title":"Setting up cloud processing with Azure Batch","text":"access files container task can modify simple JSON add additional options. “outputFiles” option lets link container place output files stored. Use “path” set location within container want file saved. filePattern select file save, either path specific file pattern match multiple files. Note file upload occurs task completes task ends without completing files saved. defined two “outputFiles” one save results created derived-data one store stdout.txt stderr.txt files show console output error output. stdout files located working directory task need “../” Adding input files much simpler, case just need supply name container autoStorageContainerName option. files container copied working directory task. addition, changed commandLine run bash script stored scripts folder. bash script necessary simple example useful want run multiple scripts anything else commandLine running script. Next need replace <sastoken> placeholder template value sastoken variable created save resulting file. avoid saving sastoken template script won’t accidentally get shared others. can delete script file launch task since easy recreate needed. Follow process create pool, job task, time new JSON file. delete modified JSON file contains sastoken Check task status confirm files uploaded container Download files want save locally. Delete analyses folder container remove files. doesn’t happen right away try leave things since long term storage solutions don’t want clutter container. delete files container don’t supply name argument Delete job pool longer charged. Note local copy machine copy files analysis.","code":"{   \"id\": \"test_outFile\",   \"commandLine\": \"sh analyses/scripts/run_script.sh\",   \"resourceFiles\": [{         \"autoStorageContainerName\": \"sendicott\"     }     ],   \"outputFiles\": [     {     \"destination\": {             \"container\": {                 \"containerUrl\": \"https://ecdcwls.blob.core.windows.net/sendicott/?<sastoken>\",                 \"path\": \"logs\"             }         },         \"filePattern\": \"../std*.txt\",         \"uploadOptions\": {             \"uploadCondition\": \"taskcompletion\"         }     },     {         \"destination\": {             \"container\": {                 \"containerUrl\": \"https://ecdcwls.blob.core.windows.net/sendicott/?<sastoken>\",                 \"path\": \"analyses/data/derived-data/output_price2.csv\"             }         },         \"filePattern\": \"analyses/data/derived-data/output_price2.csv\",         \"uploadOptions\": {             \"uploadCondition\": \"taskcompletion\"         }     }     ],     \"containerSettings\": {         \"imageName\": \"rocker/r-ubuntu:jammy\",         \"containerRunOptions\": \"--rm\"     },     \"userIdentity\": {         \"autoUser\": {             \"scope\": \"task\",             \"elevationLevel\": \"admin\"         }     } } sed 's/<sastoken>/'${sastoken//&/\\\\&}'/g' cloud_config/template_task_with_file_in_out.json > cloud_config/task_to_use.json az batch pool create --json-file cloud_config/template_pool_cli.json az batch job create --pool-id test_pool_json_cli --id \"test_job\" az batch task create --json-file cloud_config/task_to_use.json --job-id test_job  rm cloud_config/task_to_use.json az batch task show --job-id test_job --task-id test_outFile --query \"{state: state, executionInfo: executionInfo}\" --output jsonc  az storage blob list -c sendicott --account-name ecdcwls --sas-token $sastoken --query \"[].{name:name}\" az storage copy -s https://ecdcwls.blob.core.windows.net/sendicott/analyses/data/derived-data?$sastoken -d analyses/data --recursive az storage remove -c sendicott --account-name ecdcwls --sas-token $sastoken -n analyses --recursive az storage remove -c sendicott --account-name ecdcwls --sas-token $sastoken  --recursive az batch job delete --job-id test_job az batch pool delete --pool-id test_pool_json_cli  az batch job list --query \"[].{id:id, state:state}\" az batch pool list --query \"[].{id:id, state:state}\""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"run-tasks-in-parallel","dir":"Articles","previous_headings":"","what":"Run tasks in parallel","title":"Setting up cloud processing with Azure Batch","text":"truly take advantage cloud may want run multiple tasks across multiple cores one node multiple nodes pool. See vignette(\"Parallelization\", package = \"cloudDemo\") examples use autoscaling.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/cloudSetup.html","id":"install-azcopy-if-needed","dir":"Articles","previous_headings":"","what":"Install AzCopy if needed","title":"Setting up cloud processing with Azure Batch","text":"AzCopy another command line tool used az storage commands . automatically installed first time run one instructions downloading . Download azcopy https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10 Unzip easy access directory ie C:\\ C:\\Users\\username need navigate command line directory run commands unless add azcopy PATH.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/parallelization.html","id":"running-the-analysis-in-parallel","dir":"Articles","previous_headings":"","what":"Running the analysis in parallel","title":"Parallelization","text":"far analysis run sequentially able take advantage multiple cores available cloud machine. make use parallel computing can set script run model separate core. example simple added delay function can see benefit running parallel. many ways explain options. One option create parallel backend R using something like future package. can quite straight forward packages connect familiar methods iterating (eg loops, lapply purrr::map). can get bit tricky typically running parts script multiple cores need make sure right dependencies available workers. future manages part see https://future.futureverse.org/articles/future-4-issues.html tips fails.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/parallelization.html","id":"using-the-future-and-furrr-packages","dir":"Articles","previous_headings":"Running the analysis in parallel","what":"Using the future and furrr packages","title":"Parallelization","text":"future sets infrastructure needed run things background. initialize run future::plan(\"multisession\") use future::availableCores() default. furrr parallelized version purrr allows iterate elements list separate cores. See script “analyses/02_run_model_furrr.R” example.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/parallelization.html","id":"using-future-and-foreach","dir":"Articles","previous_headings":"Running the analysis in parallel","what":"Using future and foreach","title":"Parallelization","text":"usually use loops foreach package might easier use. can used future create backend using doFuture package. See script “analyses/scripts/03_run_model_foreach.R” example.","code":""},{"path":"https://landscitech.github.io/cloudDemo/articles/parallelization.html","id":"running-the-tasks-in-parallel-on-multiple-virtual-machines","dir":"Articles","previous_headings":"","what":"Running the tasks in parallel on multiple virtual machines","title":"Parallelization","text":"Instead setting script run parallel one machine can split job multiple tasks can run independently separate machines. useful task contained separate process one iteration fails impact rest. downside whole script must run task node set dependencies installed separately. set need pass argument R script task run tell iteration run. bash command run one iteration look like: R script “analyses/scripts/04_run_model_multitask.R” commandArgs(trailingOnly = TRUE) used access number passed script (eg. 1). number used select variable test name output task unique way. output task saved downloaded can compile results create figure.  example run whole analysis command line see “analyses/scripts/run_azure_autoscale.sh” also serves example setting autoscaling. Autoscaling automatically increases decreases number nodes pool depending many tasks waiting start many completed.","code":"Rscript analyses/scripts/04_run_model_multitask.R 1 r2_tab <- list.files(here::here(\"analyses/data/derived-data\"), pattern = \"*.csv\", full.names = TRUE) |>   purrr::map_dfr(read.csv) |>    dplyr::mutate(variable = reorder(variable, r.squared))  ggplot2::ggplot(r2_tab, ggplot2::aes(variable, r.squared))+   ggplot2::geom_col()"},{"path":"https://landscitech.github.io/cloudDemo/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sarah Endicott. Author, maintainer, copyright holder.","code":""},{"path":"https://landscitech.github.io/cloudDemo/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Endicott S (2025). cloudDemo: Demo Cloud Project. R package version 0.0.0.9000, https://github.com/LandSciTech/cloudDemo.","code":"@Manual{,   title = {cloudDemo: Demo Cloud Project},   author = {Sarah Endicott},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://github.com/LandSciTech/cloudDemo}, }"},{"path":"https://landscitech.github.io/cloudDemo/index.html","id":"clouddemo","dir":"","previous_headings":"","what":"Demo Cloud Project","title":"Demo Cloud Project","text":"repository hosts example data configuration files setting R analyses cloud Azure Batch. Articles give detailed instructions setting analysis using Azure CLI command line tool. analysis folder contains scripts data mock analysis cloud_config contains template JSON files use Azure CLI","code":""},{"path":"https://landscitech.github.io/cloudDemo/reference/cloudDemo-package.html","id":null,"dir":"Reference","previous_headings":"","what":"cloudDemo: Demo Cloud Project — cloudDemo-package","title":"cloudDemo: Demo Cloud Project — cloudDemo-package","text":"repo demonstrating use cloud typical analysis R","code":""},{"path":[]},{"path":"https://landscitech.github.io/cloudDemo/reference/cloudDemo-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"cloudDemo: Demo Cloud Project — cloudDemo-package","text":"Maintainer: Sarah Endicott sarah.endicott@canada.ca (ORCID) [copyright holder]","code":""},{"path":"https://landscitech.github.io/cloudDemo/reference/do_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the model for any variable — do_mod","title":"Run the model for any variable — do_mod","text":"Run linear model variable vs mpg mtcars data set extract r squared.","code":""},{"path":"https://landscitech.github.io/cloudDemo/reference/do_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the model for any variable — do_mod","text":"","code":"do_mod(x)"},{"path":"https://landscitech.github.io/cloudDemo/reference/do_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the model for any variable — do_mod","text":"x variable name mtcars","code":""},{"path":"https://landscitech.github.io/cloudDemo/reference/do_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run the model for any variable — do_mod","text":"data.frame variable name r.squared value","code":""}]
